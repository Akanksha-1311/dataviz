{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Tidy and Process the Billboard Dataset\n",
    "The goal of this homework is to **tidy** the Billboard dataset and perform some basic analysis and visualization.\n",
    "\n",
    "You will demonstrate your understanding of data tidying principles and your ability to manipulate and visualize data using Python.\n",
    "\n",
    "\n",
    "\n",
    "The Billboard dataset comes with **76 columns** corresponding to the chart position of each song from `x1st.week` through `x76th.week`. This is a classic example of **wide** data that needs to be **melted** (unpivoted) into a long (tidy) format.\n",
    "\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Project Setup**: Follow the instructions on how to set up your Python and Jupyter (or VSCode) environment, as well as how to clone or download our repository. These can be found in the class notes.\n",
    "\n",
    "2. **Dataset Path**: Verify the path to the CSV file (e.g. `\"../../Datasets/billboard.csv\"`). Adjust if necessary.\n",
    "\n",
    "3. **Load** the Billboard CSV into a DataFrame with `pd.read_csv()`.\n",
    "\n",
    "4. **Melt/Unpivot** the 76 weekly columns (`x1st.week` through `x76th.week`) into two new columns:\n",
    "\n",
    "    - `week` (indicating which week of the chart it is, e.g., 1, 2, 3...)\n",
    "\n",
    "    - `rank` (the song's chart position for that week).\n",
    "\n",
    "    - This is typically done using `pd.melt()` or `pd.wide_to_long()`.\n",
    "\n",
    "5. **Clean** the `week` values so that they are numeric (1 to 76) instead of strings like `\"x1st.week\"`.\n",
    "\n",
    "6. **Create a `date` column** that indicates the exact date on the chart for each row, using:\n",
    "   ```\n",
    "   date = date.entered + (week - 1) * 7 days\n",
    "   ```\n",
    "    - You may want to transform `date.entered` in a `datetime` format (you may need to convert it with `pd.to_datetime()` check documentation).\n",
    "\n",
    "7. **Split** the data into two tables:\n",
    "\n",
    "    1. **songs** table, which should contain unique song information (e.g., `song_id`, `artist`, `track`, `time`, etc.).\n",
    "\n",
    "       - Remember to drop duplicates so you only have one row per song.\n",
    "\n",
    "       - Generate a new `song_id` column that can be used to join back to the weekly info.\n",
    "\n",
    "    2. **positions** table, which should contain weekly data: `(song_id, week, rank, date)`.\n",
    "\n",
    "8. **Save** your tidy DataFrames to Feather format:\n",
    "\n",
    "    - Save the full “tidy” DataFrame (one row per song-week) with a filename suffix `_tidy`.\n",
    "\n",
    "    - Also save the separate `songs` and `positions` tables as separate Feather files (e.g., `songs.feather`, `positions.feather`).\n",
    "\n",
    "9. **Submission**:\n",
    "\n",
    "    - Export your completed notebook to **HTML** or **PDF**.\n",
    "\n",
    "    - If on Jupyter, select `File` > `Export Notebook As` > `HTML`.\n",
    "\n",
    "    - If on VSCode, use `Jupyter: Export to HTML` from the command palette.\n",
    "\n",
    "    - Submit your exported file on Canvas.\n",
    "\n",
    "\n",
    "\n",
    " ### Dataset Overview\n",
    "\n",
    " The dataset consists of songs and their weekly chart positions on the Billboard Hot 100. It has the following main columns:\n",
    "\n",
    " - `year`: The year the song entered the chart.\n",
    " - `artist`: The artist of the song.\n",
    " - `track`: The title of the song.\n",
    " - `time`: The duration of the song.\n",
    " - `date.entered`: The date the song first entered the chart.\n",
    " - `x1st.week` to `x76th.week`: The chart position of the song for each of the 76 weeks (1 = highest rank, 100 = lower rank).\n",
    "\n",
    "\n",
    "\n",
    " ### Goals (Detailed)\n",
    "\n",
    " 1. **Load** the Billboard dataset from CSV into a pandas DataFrame.\n",
    "\n",
    " 2. **Tidy** the data by converting the weekly columns into a single `week` column (numeric) and a `rank` column.\n",
    "\n",
    " 3. **Compute** an exact `date` for each row by adding `(week - 1) * 7 days` to the `date.entered`.\n",
    "\n",
    " 4. **Split** the data into:\n",
    "\n",
    "    - **songs**: (One row per song) containing static info and a new `song_id`.\n",
    "\n",
    "    - **positions**: (One row per song-week) containing columns: `[song_id, week, rank, date]`.\n",
    "\n",
    " 5. **Save** everything to Feather files (or CSV if you prefer, but Feather is recommended).\n",
    "\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Billboard dataset\n",
    "df_bill = pd.read_csv(\"../../Datasets/billboard.csv\")  # Adjust path if needed\n",
    "\n",
    "# Let's quickly check the first few rows to confirm the structure.\n",
    "df_bill.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The dataset has columns like:\n",
    "\n",
    "\n",
    "\n",
    "  - **year**, **artist.inverted**, **track**, **time**, **genre**, etc. (Song info)\n",
    "\n",
    "  - **date.entered**, **date.peaked** (Chart-related dates)\n",
    "\n",
    "  - **x1st.week** through **x76th.week** (Chart positions over 76 weeks)\n",
    "\n",
    "\n",
    "\n",
    "  Our objective is to **melt** these weekly columns into a single `week` and `rank` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Melt/unpivot the data into a \"tidy\" format.\n",
    "# HINT: you can use pd.melt(). \n",
    "# We'll create a new DataFrame, for example df_tidy.\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  After melting, each row should represent **one song** in **one week**. However, the `week` column will have strings like `\"x1st.week\"`, `\"x2nd.week\"`, etc. Let's clean those up and create a numeric week column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Convert the week column to numeric (strip the \"x\", remove \".week\", etc.)\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Now, `week` should be 1, 2, 3, ... 76. Next, we want to calculate the **exact date** on the chart for each row by adding `(week - 1) * 7 days` to `date.entered`. Create a column named `\"date\"` to hold the result. Make sure `date.entered` is converted to datetime first, if it isn't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create the 'date' column: date = date.entered + (week - 1)*7 days\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 5. Split into Two Tables\n",
    "\n",
    "  **Why split?** We often separate the **static** song info (e.g., artist, track, time, genre) from the **weekly** chart performance (week, rank, date).\n",
    "\n",
    "  - **Songs Table**: Contains unique identifiers for each song plus basic metadata.\n",
    "\n",
    "  - **Positions Table**: Contains `(song_id, week, rank, date)`, referencing the **song_id** from the songs table.\n",
    "\n",
    "\n",
    "\n",
    "  Generate a new `song_id` for each unique song, then merge/join this `song_id` back into the melted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Create a songs table (unique rows). Assign a song_id. \n",
    "# Then merge that ID back into the main tidy DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 6. Create the Positions Table\n",
    "\n",
    "  Once the `song_id` is part of the melted DataFrame, we can select the columns `(song_id, week, rank, date)` into a separate DataFrame called **positions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By the end of this process you should have:\n",
    "\n",
    " - A **songs** table with unique song info and a `song_id` for each song (keep song names, artists, etc.)\n",
    "\n",
    " - A **positions** table with `(song_id, week, rank, date)` for each song-week.\n",
    "\n",
    " For example:\n",
    "\n",
    " songs table:\n",
    "\n",
    " | song_id | artist         | track          | time  | year |\n",
    " |---------|----------------|----------------|-------|------|\n",
    " | 1       | The Beatles    | Hey Jude       | 3:35  | 1968 |\n",
    " | 2       | Elton John     | Rocket         | 3:10  | 1972 |\n",
    " | 3       | Whitney Houston | I Will Always  | 4:30  | 1992 |\n",
    " | ...     | ...            | ...            | ...   | ...  |\n",
    "\n",
    "\n",
    " positions table:\n",
    "\n",
    " | song_id | week | rank | date       |\n",
    " |---------|------|------|------------|\n",
    " | 1       | 1    | 1    | 1968-09-14 |\n",
    " | 1       | 2    | 1    | 1968-09-21 |\n",
    " | 1       | 3    | 1    | 1968-09-28 |\n",
    " | ...     | ...  | ...  | ...        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 7. Save Tidy Data to Feather\n",
    "\n",
    "  We want to save:\n",
    "\n",
    "  - The **complete tidy** DataFrame (one row per song-week) with a filename suffix `_tidy`.\n",
    "\n",
    "  - The **songs** and **positions** tables as separate Feather files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Basic Analysis\n",
    "\n",
    "\n",
    "\n",
    " Below are some guided analyses to help you get started. Feel free to explore more on your own!\n",
    "\n",
    "\n",
    "\n",
    " ### A. Only songs that reached top 10\n",
    "\n",
    " 1. Use `query()` to filter rows in `positions` for `rank <= 10`.\n",
    "\n",
    " 2. Merge or join with the `songs` table to get the song details.\n",
    "\n",
    "\n",
    "\n",
    " **Hint**: Remember you can drop duplicates if you only want the list of unique songs that reached top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### B. How long did each song stay in the top 10?\n",
    "\n",
    "\n",
    "\n",
    " 1. Filter `positions` for `rank <= 10`.\n",
    "\n",
    " 2. Group by `song_id` and count the number of rows. This gives `weeks_in_top_10`.\n",
    "\n",
    " 3. Merge back with the `songs` table to display the track/artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### C. In which week did each song *first* reach the top 10?\n",
    "\n",
    "\n",
    "\n",
    " 1. Again filter for `rank <= 10`.\n",
    "\n",
    " 2. Group by `song_id` and find the minimum `week` value. Call this `week_reached_top_10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Part 2 - Visualization\n",
    "\n",
    "\n",
    "\n",
    " For this part, you may use **Altair** (*Preferable!*), **Matplotlib**, **Seaborn**, or any other Python visualization library.\n",
    "\n",
    "\n",
    "\n",
    " Below are some suggested questions and plots:\n",
    "\n",
    "\n",
    "\n",
    " 1. **Histogram of Weeks in the Top 10**\n",
    "\n",
    "    - How many songs stayed for 1 week vs. 2 weeks vs. 10 weeks in the top 10?\n",
    "\n",
    "    - Plot this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Example: Histogram of the number of weeks each song stayed in the top 10.\n",
    "# (Assuming you've created a 'weeks_in_top_10' table or series.)\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. **Line Chart of a Song's Rank Over Time**\n",
    "\n",
    "    - Pick a well-known song from the dataset (e.g., one of the most weeks at #1).\n",
    "\n",
    "    - Plot its `rank` vs. `date` (or `week`).\n",
    "\n",
    "    - The line should show how the rank changes over consecutive weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the original `positions` DataFrame to plot a song's rank over time.\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. **Distribution of Peak Ranks**\n",
    "\n",
    "    - For each song, find its **best** (lowest number) rank.\n",
    "\n",
    "    - Plot a histogram of these peak positions. Where do most songs peak? (#1, #5, #20, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Bonus: Additional Analysis (Optional, but will give you extra credit!)\n",
    "\n",
    " *(Add more charts and visualizations as you see fit!)*\n",
    "\n",
    " Be creative and explore the dataset! showcase at least a new plot or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your extra analyses here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ### Final Instructions\n",
    "\n",
    " 1. Make sure your notebook runs from top to bottom without errors.\n",
    "\n",
    " 2. Export it to HTML or PDF.\n",
    "\n",
    " 3. Submit via Canvas.\n",
    "\n",
    "\n",
    "\n",
    " Good luck and have fun exploring the Billboard dataset!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
